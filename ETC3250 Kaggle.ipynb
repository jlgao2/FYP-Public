{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from pathlib2 import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.getcwd()+\"/data\")\n",
    "PATH = DATA_PATH/\"kaggle\"\n",
    "TRAIN_PATH = PATH/\"Train/\"\n",
    "TEST_PATH = PATH/\"Test/\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TEST_PATH.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "     \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "bs = 128\n",
    "\n",
    "cpu = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.genfromtxt(DATA_PATH/'sketches_train.csv', delimiter=',', dtype=np.uint8)\n",
    "train_x = train_x/256\n",
    "\n",
    "test_x = np.genfromtxt(DATA_PATH/'sketches_test.csv', delimiter=',', dtype=np.uint8)\n",
    "test_x = test_x/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.genfromtxt(DATA_PATH/'labels_np.csv', delimiter=',', dtype=np.uint8) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[511]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for row in train_x:\n",
    "    arr = row\n",
    "    i += 1\n",
    "    sqr = arr.reshape(28,28)\n",
    "    img = Image.fromarray(sqr)\n",
    "    img.save(str(TRAIN_PATH)+\"/\"+str(i)+\".png\", \"PNG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 0\n",
    "for row in test_x:\n",
    "    arr = row\n",
    "    i += 1\n",
    "    sqr = arr.reshape(28,28)\n",
    "    img = Image.fromarray(sqr)\n",
    "    img.save(str(TEST_PATH)+\"/\"+str(i)+\".png\", \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6000, 784]) torch.Size([6000]) torch.Size([1200, 784])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x = map(\n",
    "    torch.tensor, (train_x, train_y, test_x)\n",
    ")\n",
    "print(train_x.shape, train_y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.float().to(dev).view(-1, 1, 28, 28)\n",
    "test_x = test_x.float().to(cpu).view(-1, 1, 28, 28)\n",
    "train_y = train_y.long().to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(28,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_ds = TensorDataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds = random_split(sketch_ds, [4000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[50][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, shuffle=True, batch_size=bs)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10)/ math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Mnist_Logistic().float().to(dev)\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    acc2 = accuracy(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb), acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(epoch):\n",
    "    torch.save(model.state_dict(), \"kagglemodel_{}.model\".format(epoch))\n",
    "    print(\"Checkpoint saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            acc = accuracy(model(xb), yb)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums, acc2 = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        if 0.35 > val_loss:\n",
    "            torch.save(model,\"kagglemodel_{}.model\".format(epoch))\n",
    "            print(\"Checkpoint saved\")\n",
    "        \n",
    "        print(epoch, val_loss, acc, acc2)\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dl, valid_dl = get_data(train_ds, test_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "plt.pyplot.imshow(train_x.cpu()[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bs = 64\n",
    "lr = 0.1\n",
    "epochs = 10\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Unit1, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, kernel_size=1, out_channels=out_channels, stride=1, padding=0)\n",
    "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        output = self.bn(output)\n",
    "        output = self.relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(SimpleNet,self).__init__()\n",
    "        \n",
    "        #Create 14 layers of the unit with max pooling in between\n",
    "        self.unit1 = Unit(in_channels=1,out_channels=32)\n",
    "        self.unit2 = Unit(in_channels=32, out_channels=64)\n",
    "        self.unit3 = Unit(in_channels=64, out_channels=128)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit4 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit5 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit6 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit7 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit8 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
    "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.unit12 = Unit1(in_channels=128, out_channels=128)\n",
    "        self.unit13 = Unit1(in_channels=128, out_channels=128)\n",
    "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        \n",
    "        #Add all the units into the Sequential layer in exact order\n",
    "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
    "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
    "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=128,out_features=num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        output = output.view(-1,128)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (unit1): Unit(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit2): Unit(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit3): Unit(\n",
       "    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unit4): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit5): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit6): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit7): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unit8): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit9): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit10): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit11): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unit12): Unit1(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit13): Unit1(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (unit14): Unit(\n",
       "    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  (net): Sequential(\n",
       "    (0): Unit(\n",
       "      (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): Unit(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Unit(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (10): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (11): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (12): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Unit1(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): Unit1(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (16): Unit(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (17): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class SimpleNet(nn.Module):\n",
    "#     def __init__(self, num_classes=6):\n",
    "#         super(SimpleNet, self).__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "\n",
    "#         self.conv4 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "\n",
    "#         self.fc = nn.Linear(in_features=14 * 14 * 24, out_features=num_classes)\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         output = self.conv1(input)\n",
    "#         output = self.relu1(output)\n",
    "\n",
    "#         output = self.conv2(output)\n",
    "#         output = self.relu2(output)\n",
    "\n",
    "#         output = self.pool(output)\n",
    "\n",
    "#         output = self.conv3(output)\n",
    "#         output = self.relu3(output)\n",
    "\n",
    "#         output = self.conv4(output)\n",
    "#         output = self.relu4(output)\n",
    "\n",
    "#         output = output.view(-1, 14 * 14 * 24)\n",
    "\n",
    "#         output = self.fc(output)\n",
    "\n",
    "#         return output\n",
    "    \n",
    "model = SimpleNet(num_classes=6)\n",
    "\n",
    "opt   = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3794380965232849 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8828, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.8828, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9023, device='cuda:0'), tensor(0.9219, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "1 0.4382816245555878 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8789, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9375, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "2 0.4264542098045349 tensor(1., device='cuda:0') (tensor(0.9023, device='cuda:0'), tensor(0.9023, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.8867, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "3 0.3932993655204773 tensor(1., device='cuda:0') (tensor(0.9336, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9414, device='cuda:0'), tensor(0.8867, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9414, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "4 0.39587940835952756 tensor(1., device='cuda:0') (tensor(0.9258, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9231, device='cuda:0'))\n",
      "\n",
      "\n",
      "5 0.39719373059272767 tensor(1., device='cuda:0') (tensor(0.9180, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.8906, device='cuda:0'), tensor(0.9375, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9219, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "6 0.4791881566047668 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9231, device='cuda:0'))\n",
      "\n",
      "\n",
      "7 0.4132472262382507 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9219, device='cuda:0'), tensor(0.8711, device='cuda:0'), tensor(0.9219, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9231, device='cuda:0'))\n",
      "\n",
      "\n",
      "8 0.4924663360118866 tensor(1., device='cuda:0') (tensor(0.9141, device='cuda:0'), tensor(0.8711, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.8672, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.8867, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9038, device='cuda:0'))\n",
      "\n",
      "\n",
      "9 0.43550760245323183 tensor(1., device='cuda:0') (tensor(0.9102, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.8867, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9087, device='cuda:0'))\n",
      "\n",
      "\n",
      "10 0.5031898560523986 tensor(1., device='cuda:0') (tensor(0.9102, device='cuda:0'), tensor(0.8867, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.8672, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.8789, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9231, device='cuda:0'))\n",
      "\n",
      "\n",
      "11 0.5448112707138062 tensor(1., device='cuda:0') (tensor(0.9062, device='cuda:0'), tensor(0.8555, device='cuda:0'), tensor(0.8828, device='cuda:0'), tensor(0.8711, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9183, device='cuda:0'))\n",
      "\n",
      "\n",
      "12 0.4405217444896698 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9023, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9231, device='cuda:0'))\n",
      "\n",
      "\n",
      "13 0.39573303556442263 tensor(1., device='cuda:0') (tensor(0.9102, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9219, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9183, device='cuda:0'))\n",
      "\n",
      "\n",
      "14 0.39013038730621336 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8945, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.9375, device='cuda:0'))\n",
      "\n",
      "\n",
      "15 0.3915658175945282 tensor(1., device='cuda:0') (tensor(0.9336, device='cuda:0'), tensor(0.8984, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9375, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.9327, device='cuda:0'))\n",
      "\n",
      "\n",
      "16 0.38074964022636415 tensor(1., device='cuda:0') (tensor(0.9219, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9375, device='cuda:0'), tensor(0.9023, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.9375, device='cuda:0'))\n",
      "\n",
      "\n",
      "17 0.40580312299728394 tensor(1., device='cuda:0') (tensor(0.9180, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9141, device='cuda:0'), tensor(0.9375, device='cuda:0'))\n",
      "\n",
      "\n",
      "18 0.41290492248535154 tensor(1., device='cuda:0') (tensor(0.9219, device='cuda:0'), tensor(0.9336, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9375, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9102, device='cuda:0'), tensor(0.9471, device='cuda:0'))\n",
      "\n",
      "\n",
      "19 0.4191609435081482 tensor(1., device='cuda:0') (tensor(0.9297, device='cuda:0'), tensor(0.8906, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.9180, device='cuda:0'), tensor(0.9258, device='cuda:0'), tensor(0.9062, device='cuda:0'), tensor(0.9297, device='cuda:0'), tensor(0.9375, device='cuda:0'))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "lr = 0.0005\n",
    "epochs = 20\n",
    "opt = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "fit(epochs, model, loss_func, opt, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = torch.load(str(PATH/'035.model')).to(cpu)\n",
    "model_best.eval()\n",
    "test_y = []\n",
    "for row in test_x:\n",
    "    res = model_best(row.unsqueeze(0))\n",
    "    test_y.append(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for row in test_y:\n",
    "    pred = torch.argmax(row[0], dim=-1)\n",
    "    preds.append(pred.item()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = { 1: 'boomerang', 2:'kangaroo', 3:'crab', 4:'cactus', 5:'flip flops', 6:'banana' }\n",
    "\n",
    "preds2 = []\n",
    "for item in preds:\n",
    "    preds2.append(key[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cactus\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 653\n",
    "plt.pyplot.imshow(test_x[x].reshape((28, 28)), cmap=\"gray\")\n",
    "print(preds2[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"results.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(preds2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
